{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward Propagation with Mini-Batch Stochastic Gradiant Descent\n",
    "\n",
    "## Spesifikasi\n",
    "- Jumlah hidden layer maksimal 10\n",
    "- Jumlah node dalam setiap hidden layer dapat bervariasi\n",
    "- Fully-connected layer\n",
    "- Fungsi aktivasi berupa sigmoid untuk semua hidden layer maupun output layer\n",
    "- Node output berjumlah 1\n",
    "- Program memberikan pilihan untuk menggunakan momentum atau tidak\n",
    "- Program mengimplementasikan mini-batch stochastic gradient descent\n",
    "- Implementasi incremental dengan setting batch-size=1 dan implementasi batch dengan setting batchsize=jumlah\n",
    "data.\n",
    "\n",
    "Algoritma ini akan diuji dengan data weather (tennis) yang diambil dari wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, \n",
    "                 input_nodes,\n",
    "                 hidden_nodes=[],\n",
    "                 output_nodes=1,\n",
    "                 batch_size=4,\n",
    "                 learning_rate=1e-4,\n",
    "                 momentum=0):\n",
    "        assert(input_nodes >= 1)\n",
    "        assert(0 <= len(hidden_nodes) <= 10)\n",
    "        assert(batch_size >= 1)\n",
    "        \n",
    "        self.layers = self._init_layers(input_nodes, hidden_nodes, output_nodes)\n",
    "        self.batchSize = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.params_values = self._init_weights()\n",
    "\n",
    "        \n",
    "    def _init_layers(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        layers = []\n",
    "        layers.append(input_nodes)\n",
    "        for hidden_layer in hidden_nodes:\n",
    "            layers.append(hidden_layer)\n",
    "        layers.append(output_nodes)\n",
    "        \n",
    "        return layers\n",
    "        \n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"\n",
    "        Initiate weights and bias weights for the neural network\n",
    "        \"\"\"\n",
    "        params_values = {}\n",
    "        for idx in range(len(self.layers)-1):\n",
    "            layer_input_size = self.layers[idx]\n",
    "            layer_output_size = self.layers[idx+1]\n",
    "            \n",
    "            # Weight\n",
    "            params_values['W' + str(idx+1)] = np.random.randn(layer_output_size, layer_input_size) * 0.1\n",
    "            \n",
    "            # Bias Weight\n",
    "            params_values['b' + str(idx+1)] = np.random.randn(layer_output_size, 1) * 0.1\n",
    "            \n",
    "        return params_values\n",
    "    \n",
    "    \n",
    "    def _single_layer_feed_forward(self, A_prev, W_curr, b_curr):\n",
    "        \"\"\"\n",
    "        Feed forward for single layer in neural network\n",
    "        \"\"\"\n",
    "        Z_curr = np.dot(W_curr, A_prev) + b_curr\n",
    "        return self._sigmoid(Z_curr), Z_curr\n",
    "        \n",
    "        \n",
    "    def _full_feed_forward(self, X):\n",
    "        memory = {}\n",
    "        A_curr = X\n",
    "        \n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            print(self.layers[idx])\n",
    "            A_prev = A_curr\n",
    "            W_curr = self.params_values['W' + str(idx+1)]\n",
    "            b_curr = self.params_values['b' + str(idx+1)]\n",
    "            \n",
    "            A_curr, Z_curr = self._single_layer_feed_forward(A_prev, W_curr, b_curr)\n",
    "            \n",
    "            memory['A' + str(idx)] = A_prev\n",
    "            memory['Z' + str(idx+1)] = Z_curr\n",
    "            \n",
    "        return A_curr, memory\n",
    "        \n",
    "    \n",
    "    def _single_layer_backward_prop(self, dA_curr, W_curr, b_curr, Z_curr, A_prev):\n",
    "        m = A_prev.shape[1]\n",
    "        \n",
    "        dZ_curr = self._sigmoid_backward(dA_curr, Z_curr)\n",
    "        dW_curr = np.dot(dZ_curr, A_prev) / m\n",
    "        db_curr = np.sum(dZ_curr, axis=1, keepdims=True) / m\n",
    "        dA_prev = np.dot(W_curr.T, dZ_curr)\n",
    "        \n",
    "        return dA_prev, dW_curr, db_curr\n",
    "    \n",
    "    \n",
    "    def _full_backward_prop(self, y_hat, y, memory):\n",
    "        grads_values = {}\n",
    "        m = y.shape[1]\n",
    "        y = y.reshape(y_hat.shape)\n",
    "        \n",
    "        dA_prev = -(np.divide(Y, y_hat) - np.divide(1-y, 1-y_hat))\n",
    "        \n",
    "        for layer_idx_prev, layer in reversed(enumerate(self.layers)):\n",
    "            layer_idx_curr = layer_idx_prev + 1\n",
    "            \n",
    "            dA_curr = dA_prev\n",
    "            \n",
    "            A_prev = memory['A' + str(layer_idx_prev)]\n",
    "            Z_curr = memory['Z' + str(layer_idx_curr)]\n",
    "            W_curr = self.params_values['W' + str(layer_idx_curr)]\n",
    "            b_curr = self.params_values['b' + str(layer_idx_curr)]\n",
    "            \n",
    "            dA_prev, dW_curr,db_curr = self._single_layer_backward_prop(dA_curr, W_curr, b_curr, Z_curr, A_prev)\n",
    "            \n",
    "            grads_values['dW' + str(layer_idx_curr)] = dW_curr\n",
    "            grads_values['db' + str(layer_idx_curr)] = db_curr\n",
    "            \n",
    "        return grads_values\n",
    "    \n",
    "    \n",
    "    def _update(grads_values):\n",
    "        for layer_idx, layer in enumerate(self.layers):\n",
    "            self.params_values['W' + str(layer_idx)] -= self.learning_rate * grads_values['dW' + str(layer_idx)]\n",
    "            self.params_values['b' + str(layer_idx)] -= self.learning_rate * grads_values['db' + str(layer_idx)]\n",
    "    \n",
    "    \n",
    "    def _sigmoid(self, weighted_sum):\n",
    "        return 1/(1+np.exp(-weighted_sum))\n",
    "    \n",
    "    \n",
    "    def _sigmoid_backward(self, delta, weighted_sum):\n",
    "        sigmoid = self._sigmoid(weighted_sum)\n",
    "        return delta * sigmoid * (1 - sigmoid)\n",
    "    \n",
    "        \n",
    "    def _calc_error(self, output, target):\n",
    "        return math.pow(output-target, 2)/2\n",
    "    \n",
    "    \n",
    "    def _calc_accuracy(self, output, target):\n",
    "        count_correct = 0\n",
    "        for i in range(len(output)):\n",
    "            if output[i] == target[i]:\n",
    "                count_correct += 1\n",
    "        return count_correct / len(output)\n",
    "    \n",
    "    \n",
    "    def train(self, X, y, epochs):\n",
    "        cost_history = []\n",
    "        accuracy_history = []\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            y_hat, cache = self._full_feed_forward(X)\n",
    "            cost = self._calc_error(y_hat, y)\n",
    "            cost_history.append(cost)\n",
    "            accuracy = self._calc_accuracy(y_hat, y)\n",
    "            accuracy_history.append(accuracy)\n",
    "            \n",
    "            grads_values = self._full_backward_prop(y_hat, y, cache)\n",
    "            self.params_values = update(grads_values)\n",
    "            \n",
    "        return self.params_values, cost_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (8,7) and (12,7) not aligned: 7 (dim 1) != 12 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-1478b039ab29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# print(model.params_values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-85-64dbe8e1ba5b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_feed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcost_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-64dbe8e1ba5b>\u001b[0m in \u001b[0;36m_full_feed_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mb_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mA_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_layer_feed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mmemory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-64dbe8e1ba5b>\u001b[0m in \u001b[0;36m_single_layer_feed_forward\u001b[0;34m(self, A_prev, W_curr, b_curr)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mFeed\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msingle\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mZ_curr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_prev\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_curr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ_curr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_curr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (8,7) and (12,7) not aligned: 7 (dim 1) != 12 (dim 0)"
     ]
    }
   ],
   "source": [
    "dataset = arff.loadarff('../data/weather.arff')\n",
    "df = pd.DataFrame(dataset[0])\n",
    "\n",
    "STR_COLUMNS = ['outlook', 'windy', 'play']\n",
    "\n",
    "for column in STR_COLUMNS:\n",
    "    df[column] = df[column].str.decode('utf-8')\n",
    "    \n",
    "df_encoded = pd.get_dummies(df, columns=['outlook', 'windy'])\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=['play'], drop_first=True)\n",
    "\n",
    "X = df_encoded.iloc[:, :7].values\n",
    "y = df_encoded.iloc[:, 7:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=17779)\n",
    "\n",
    "model = NeuralNetwork(input_nodes=7, hidden_nodes=[8], output_nodes=1)\n",
    "# print(model.params_values)\n",
    "param, costs, accs = model.train(X_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
